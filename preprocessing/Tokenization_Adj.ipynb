{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import *\n",
    "from nltk import Text\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국내 뮤비 한글 댓글\n",
    "# 국내 뮤비 영어 댓글\n",
    "# D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\show\\internal\n",
    "\n",
    "# 해외 뮤비 영어 댓글\n",
    "SOURCE_PATH = \"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data\\\\show\\\\internal\\\\\"\n",
    "# SOURCE_PATH = \"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data\\\\show\\\\overseas\\\\\"\n",
    "\n",
    "TARGET_PATH = \"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data2\\\\overseas\\\\\"\n",
    "\n",
    "FONT_PATH = \"C:\\\\WINDOWS\\FONTS\\MALGUNSL.TTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_in_directory(path, extension='.csv'):\n",
    "    file_list = os.listdir(path)\n",
    "    csv_file_list = [file for file in file_list if file.endswith(extension)]\n",
    "    return csv_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = file_list_in_directory(SOURCE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 형용사 Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj_list = list()\n",
    "for file_list in file_lists:\n",
    "    df = pd.read_csv(SOURCE_PATH + file_list, sep=',')\n",
    "    hangul_df = df[df['hangul']==True]['contents']\n",
    "\n",
    "    for idx, document in enumerate(hangul_df):\n",
    "        okt = konlpy.tag.Okt()\n",
    "        adj_words = []\n",
    "        for word in okt.pos(document, stem=True):\n",
    "            if word[1] in ['Adjective']:\n",
    "    #         if word[1] in ['Noun', 'Verb', 'Adjective']:\n",
    "                adj_words.append(word[0])\n",
    "                all_adj_list.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(all_adj_list)\n",
    "most_count = count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TARGET_PATH + \"overseas-hangul.csv\", encoding='utf-8-sig', mode='w') as f:\n",
    "    for tag in most_count:\n",
    "        f.write('{},{}\\n'.format(tag[0], tag[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영어 형용사 Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adj_list = list()\n",
    "for file_list in file_lists:\n",
    "    df = pd.read_csv(SOURCE_PATH + file_list, sep=',')\n",
    "    eng_df = df[df['hangul']==False]['contents']\n",
    "    \n",
    "    for idx, contents in enumerate(eng_df):\n",
    "        try:\n",
    "            for word in nltk.tag.pos_tag(nltk.tokenize.word_tokenize(contents)):  \n",
    "                if word[1] in ['JJ']:\n",
    "                    all_adj_list.append(word[0])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 9333),\n",
       " ('much', 6553),\n",
       " ('i', 6069),\n",
       " ('beautiful', 5195),\n",
       " ('new', 5187),\n",
       " ('first', 4298),\n",
       " ('u', 3869),\n",
       " ('other', 3631),\n",
       " ('happy', 3356),\n",
       " ('many', 3219),\n",
       " ('great', 2977),\n",
       " ('nct', 2812),\n",
       " ('same', 2711),\n",
       " ('cute', 2533),\n",
       " ('amazing', 2108),\n",
       " ('hard', 2034),\n",
       " ('different', 1990),\n",
       " ('next', 1947),\n",
       " ('bad', 1947),\n",
       " ('only', 1892),\n",
       " ('proud', 1797),\n",
       " ('such', 1792),\n",
       " ('perfect', 1565),\n",
       " ('last', 1554),\n",
       " ('Good', 1475),\n",
       " ('Happy', 1474),\n",
       " ('nice', 1460),\n",
       " ('favorite', 1415),\n",
       " ('cool', 1401),\n",
       " ('Algerian', 1361),\n",
       " ('whole', 1338),\n",
       " ('black', 1275),\n",
       " ('big', 1219),\n",
       " ('dont', 1199),\n",
       " ('real', 1177),\n",
       " ('own', 1162),\n",
       " ('everyday', 1140),\n",
       " ('talented', 1139),\n",
       " ('little', 1131),\n",
       " ('sad', 1121),\n",
       " ('queen', 1091),\n",
       " ('im', 1047),\n",
       " ('cant', 1034),\n",
       " ('hot', 1017),\n",
       " ('handsome', 1000),\n",
       " ('oh', 968),\n",
       " ('old', 943),\n",
       " ('strong', 935),\n",
       " ('sure', 932),\n",
       " ('unique', 924),\n",
       " ('Solar', 892),\n",
       " ('visual', 883),\n",
       " ('long', 863),\n",
       " ('un', 850),\n",
       " ('gorgeous', 827),\n",
       " ('udah', 819),\n",
       " ('high', 812),\n",
       " ('song', 799),\n",
       " ('awesome', 796),\n",
       " ('kalian', 789),\n",
       " ('main', 755),\n",
       " ('vocal', 750),\n",
       " ('n', 728),\n",
       " ('nya', 718),\n",
       " ('sexy', 715),\n",
       " ('girl', 712),\n",
       " ('special', 711),\n",
       " ('few', 705),\n",
       " ('full', 691),\n",
       " ('stop', 687),\n",
       " ('live', 663),\n",
       " ('wrong', 653),\n",
       " ('solar', 651),\n",
       " ('idle', 649),\n",
       " ('single', 647),\n",
       " ('pretty', 642),\n",
       " ('similar', 642),\n",
       " ('underrated', 640),\n",
       " ('like', 636),\n",
       " ('true', 623),\n",
       " ('blue', 607),\n",
       " ('popular', 606),\n",
       " ('catchy', 606),\n",
       " ('ready', 605),\n",
       " ('korean', 604),\n",
       " ('untuk', 604),\n",
       " ('una', 601),\n",
       " ('itzy', 589),\n",
       " ('Korean', 584),\n",
       " ('red', 575),\n",
       " ('top', 574),\n",
       " ('que', 572),\n",
       " ('know', 570),\n",
       " ('second', 564),\n",
       " ('right', 555),\n",
       " ('ok', 544),\n",
       " ('deep', 540),\n",
       " ('ive', 536),\n",
       " ('powerful', 527),\n",
       " ('ur', 520),\n",
       " ('stan', 515),\n",
       " ('super', 511),\n",
       " ('na', 510),\n",
       " ('short', 508),\n",
       " ('healthy', 498),\n",
       " ('daily', 489),\n",
       " ('official', 482),\n",
       " ('aesthetic', 467),\n",
       " ('um', 465),\n",
       " ('GOOD', 462),\n",
       " ('iconic', 454),\n",
       " ('sweet', 454),\n",
       " ('international', 453),\n",
       " ('GI-DLE', 450),\n",
       " ('please', 437),\n",
       " ('crazy', 433),\n",
       " ('favourite', 429),\n",
       " ('close', 426),\n",
       " ('Everyday', 424),\n",
       " ('english', 412),\n",
       " ('fixed', 412),\n",
       " ('female', 411),\n",
       " ('successful', 401),\n",
       " ('famous', 401),\n",
       " ('Queen', 399),\n",
       " ('nh', 397),\n",
       " ('white', 396),\n",
       " ('omg', 386),\n",
       " ('slow', 378),\n",
       " ('young', 373),\n",
       " ('Cant', 371),\n",
       " ('wonderful', 367),\n",
       " ('lit', 361),\n",
       " ('soft', 356),\n",
       " ('precious', 355),\n",
       " ('los', 354),\n",
       " ('addictive', 347),\n",
       " ('nal', 347),\n",
       " ('dengan', 346),\n",
       " ('possible', 345),\n",
       " ('able', 340),\n",
       " ('ng', 339),\n",
       " ('uma', 339),\n",
       " ('Such', 333),\n",
       " ('o', 332),\n",
       " ('free', 332),\n",
       " ('lucky', 330),\n",
       " ('sooo', 324),\n",
       " ('adorable', 322),\n",
       " ('el', 313),\n",
       " ('udh', 313),\n",
       " ('funny', 312),\n",
       " ('uwu', 306),\n",
       " ('late', 303),\n",
       " ('sorry', 301),\n",
       " ('English', 300),\n",
       " ('important', 299),\n",
       " ('god', 297),\n",
       " ('gay', 296),\n",
       " ('nctzen', 295),\n",
       " ('fresh', 292),\n",
       " ('original', 292),\n",
       " ('safe', 290),\n",
       " ('esta', 288),\n",
       " ('inner', 287),\n",
       " ('nanas', 287),\n",
       " ('solo', 286),\n",
       " ('small', 285),\n",
       " ('nan', 282),\n",
       " ('theyre', 281),\n",
       " ('easy', 281),\n",
       " ('ta', 280),\n",
       " ('ni', 277),\n",
       " ('glad', 277),\n",
       " ('green', 274),\n",
       " ('soo', 272),\n",
       " ('wan', 270),\n",
       " ('emotional', 268),\n",
       " ('si', 265),\n",
       " ('se', 263),\n",
       " ('mv', 262),\n",
       " ('kpop', 262),\n",
       " ('familiar', 261),\n",
       " ('nae', 260),\n",
       " ('Beautiful', 258),\n",
       " ('anniversary', 257),\n",
       " ('di', 257),\n",
       " ('dead', 256),\n",
       " ('lazy', 252),\n",
       " ('aku', 251),\n",
       " ('fav', 250),\n",
       " ('stream', 248),\n",
       " ('early', 248),\n",
       " ('incredible', 246),\n",
       " ('jealous', 246),\n",
       " ('weird', 246),\n",
       " ('fine', 238),\n",
       " ('luv', 235),\n",
       " ('magical', 235),\n",
       " ('social', 232)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(all_adj_list)\n",
    "most_count = count.most_common(200)\n",
    "most_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data2\\\\overseas\\\\\" + \"internal-english.csv\", encoding='utf-8-sig', mode='w') as f:\n",
    "    for tag in most_count:\n",
    "        f.write('{},{}\\n'.format(tag[0], tag[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
