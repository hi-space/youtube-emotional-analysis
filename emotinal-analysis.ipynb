{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_FILEPATH = \"C:\\\\Users\\\\hello\\\\Desktop\\\\interview\\\\\"\n",
    "OUTPUT_PATH = \"C:\\\\Users\\\\hello\\\\Desktop\\\\result\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from afinn import Afinn\n",
    "from konlpy.tag import Okt\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "import re\n",
    "import time\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn = Afinn(emoticons=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_in_directory(path, extension='.csv'):\n",
    "    file_list = os.listdir(path)\n",
    "    csv_file_list = [file for file in file_list if file.endswith(extension)]\n",
    "    return csv_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filepath: str, df):\n",
    "    df.to_csv(filepath, sep=',', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(source_path):\n",
    "    print(source_path)\n",
    "    df = pd.read_csv(source_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eng_score_afinn(s):\n",
    "    s = str(s)\n",
    "    try:\n",
    "        return afinn.score(s)\n",
    "    except:\n",
    "        print(\"Score Error \", s)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS = re.compile('[\\U00010000-\\U0010ffff]', flags=re.UNICODE)\n",
    "def text_cleaning(s):\n",
    "    return LETTERS.sub('', str(s))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = file_list_in_directory(SOURCE_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google trans api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator_api(text):\n",
    "    try:\n",
    "        translator = Translator()\n",
    "        comment = translator.translate(text=text, dest='en').text\n",
    "        return comment\n",
    "    except Exception as e:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## google trans page using selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_to_translate_driver():\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(\"https://translate.google.com/#view=home&op=translate&tl=en\")\n",
    "    driver.find_element_by_xpath('//*[@id=\"sugg-item-ko\"]').click()\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]').click()\n",
    "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[4]/div[1]/div[2]/div[2]').click()\n",
    "    webdriver.ActionChains(driver).send_keys(Keys.ESCAPE).perform()\n",
    "    driver.implicitly_wait(3)\n",
    "    return driver\n",
    "\n",
    "def translate(driver, source_text):\n",
    "    try:\n",
    "        elem = driver.find_element_by_xpath(\"//*[@id=\\\"source\\\"]\")\n",
    "        elem.clear()\n",
    "        elem.send_keys(source_text)\n",
    "        time.sleep(1)\n",
    "        driver.implicitly_wait(3)\n",
    "        result = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]')\n",
    "        return result.text\n",
    "    except:\n",
    "        print(source_text)\n",
    "        return source_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version 83.0.4103\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/83.0.4103.39/chromedriver_win32.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Unpack archive C:\\Users\\hello\\.wdm\\drivers\\chromedriver\\83.0.4103.39\\win32\\chromedriver.zip\n"
     ]
    }
   ],
   "source": [
    "driver = ready_to_translate_driver()\n",
    "\n",
    "def sentimental_using_afinn(filename):\n",
    "    print(filename)\n",
    "    df = load_file(SOURCE_FILEPATH + filename)\n",
    "    score_list = list()\n",
    "    translated_list = list()\n",
    "    for idx, row in df.iterrows():\n",
    "        comment = text_cleaning(row['contents'])\n",
    "        try:\n",
    "            if row['hangul'] == True:\n",
    "                time.sleep(1)\n",
    "                comment = translate(driver, comment)\n",
    "                time.sleep(1)\n",
    "        finally:\n",
    "            translated_list.append(comment)\n",
    "            score_list.append(get_eng_score_afinn(comment))\n",
    "        \n",
    "    df.insert(4, 'translate', translated_list)\n",
    "    df.insert(5, 'score(afinn)', score_list)\n",
    "    save_file(OUTPUT_PATH + filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zico-2.csv\n",
      "C:\\Users\\hello\\Desktop\\interview\\zico-2.csv\n",
      "zico-3.csv\n",
      "C:\\Users\\hello\\Desktop\\interview\\zico-3.csv\n"
     ]
    }
   ],
   "source": [
    "for filename in file_list:\n",
    "    sentimental_using_afinn(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"zico\"\n",
    "path1 = \"C://Users/hello/Desktop/interview/\" + name + \"-1.csv\"\n",
    "path2 = \"C://Users/hello/Desktop/interview/\" + name + \"-2.csv\"\n",
    "path3 = \"C://Users/hello/Desktop/interview/\" + name + \"-3.csv\"\n",
    "\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "df3 = pd.read_csv(path3)\n",
    "\n",
    "df = pd.concat([df1, df2, df3])\n",
    "df = df.drop(df.columns[[0]], axis=1)\n",
    "\n",
    "output_path = \"C://Users/hello/Desktop/result/\"\n",
    "df.to_csv(output_path + name +\".csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>contents</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>date</th>\n",
       "      <th>translate</th>\n",
       "      <th>score(afinn)</th>\n",
       "      <th>hangul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ace spades</td>\n",
       "      <td>She's so pretty</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-06T06:25:42.000Z</td>\n",
       "      <td>She's so pretty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jeikey</td>\n",
       "      <td>Like si vienes de maristas</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-05T08:49:28.000Z</td>\n",
       "      <td>Like si vienes de maristas</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max flynn</td>\n",
       "      <td>She is soooo ICONIC ❤️❤️❤️❤️❤️</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-05T00:37:37.000Z</td>\n",
       "      <td>She is soooo ICONIC ❤️❤️❤️❤️❤️</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jayy T</td>\n",
       "      <td>Am I the only one who's still shocked that tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-03T23:39:54.000Z</td>\n",
       "      <td>Am I the only one who's still shocked that tha...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kosar Beiki</td>\n",
       "      <td>How about BTS?? Weren't they the first after b...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-05-03T23:02:54.000Z</td>\n",
       "      <td>How about BTS?? Weren't they the first after b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Secret K</td>\n",
       "      <td>Love her she so humble love you Zach</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-31T05:52:41.000Z</td>\n",
       "      <td>Love her she so humble love you Zach</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Hannah Naumann</td>\n",
       "      <td>Love Zach and Ariana interviews</td>\n",
       "      <td>29</td>\n",
       "      <td>2015-10-31T04:03:24Z</td>\n",
       "      <td>Love Zach and Ariana interviews</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>abigail kidimbu</td>\n",
       "      <td>mom💗</td>\n",
       "      <td>6</td>\n",
       "      <td>2015-10-31T03:51:37Z</td>\n",
       "      <td>mom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Ashley Stephens</td>\n",
       "      <td>yay you mentioned aaron and liz c':</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-10-31T03:51:02Z</td>\n",
       "      <td>yay you mentioned aaron and liz c':</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Y P</td>\n",
       "      <td>ive never heard someone say to ariana grande w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-31T03:01:49Z</td>\n",
       "      <td>ive never heard someone say to ariana grande w...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10440 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                           contents  \\\n",
       "0         ace spades                                    She's so pretty   \n",
       "1             jeikey                         Like si vienes de maristas   \n",
       "2          max flynn                     She is soooo ICONIC ❤️❤️❤️❤️❤️   \n",
       "3             Jayy T  Am I the only one who's still shocked that tha...   \n",
       "4        Kosar Beiki  How about BTS?? Weren't they the first after b...   \n",
       "..               ...                                                ...   \n",
       "599         Secret K               Love her she so humble love you Zach   \n",
       "600   Hannah Naumann                    Love Zach and Ariana interviews   \n",
       "601  abigail kidimbu                                               mom💗   \n",
       "602  Ashley Stephens                yay you mentioned aaron and liz c':   \n",
       "603              Y P  ive never heard someone say to ariana grande w...   \n",
       "\n",
       "     likeCount                      date  \\\n",
       "0            0  2020-05-06T06:25:42.000Z   \n",
       "1            0  2020-05-05T08:49:28.000Z   \n",
       "2            0  2020-05-05T00:37:37.000Z   \n",
       "3            0  2020-05-03T23:39:54.000Z   \n",
       "4            0  2020-05-03T23:02:54.000Z   \n",
       "..         ...                       ...   \n",
       "599          0  2015-10-31T05:52:41.000Z   \n",
       "600         29      2015-10-31T04:03:24Z   \n",
       "601          6      2015-10-31T03:51:37Z   \n",
       "602          1      2015-10-31T03:51:02Z   \n",
       "603          0      2015-10-31T03:01:49Z   \n",
       "\n",
       "                                             translate  score(afinn)  hangul  \n",
       "0                                      She's so pretty           1.0   False  \n",
       "1                           Like si vienes de maristas           2.0   False  \n",
       "2                       She is soooo ICONIC ❤️❤️❤️❤️❤️           0.0   False  \n",
       "3    Am I the only one who's still shocked that tha...          -2.0   False  \n",
       "4    How about BTS?? Weren't they the first after b...           0.0   False  \n",
       "..                                                 ...           ...     ...  \n",
       "599               Love her she so humble love you Zach           7.0   False  \n",
       "600                    Love Zach and Ariana interviews           3.0   False  \n",
       "601                                                mom           0.0   False  \n",
       "602                yay you mentioned aaron and liz c':           0.0   False  \n",
       "603  ive never heard someone say to ariana grande w...           0.0   False  \n",
       "\n",
       "[10440 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
