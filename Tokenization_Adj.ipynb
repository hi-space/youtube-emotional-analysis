{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "from konlpy.corpus import kolaw\n",
    "from konlpy.tag import *\n",
    "from nltk import Text\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국내 뮤비 한글 댓글\n",
    "# 국내 뮤비 영어 댓글\n",
    "# 해외 뮤비 영어 댓글\n",
    "\n",
    "SOURCE_PATH = \"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data\\\\filtered-show\\\\overseas\\\\\"\n",
    "TARGET_PATH = \"D:\\\\02-yscec\\\\2020-1\\\\DataVisualization\\\\final-term\\\\preprocess_data\\\\tokenized-show\\\\internal\\\\\"\n",
    "\n",
    "FONT_PATH = \"C:\\\\WINDOWS\\FONTS\\MALGUNSL.TTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_in_directory(path, extension='.csv'):\n",
    "    file_list = os.listdir(path)\n",
    "    csv_file_list = [file for file in file_list if file.endswith(extension)]\n",
    "    return csv_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_lists = file_list_in_directory(SOURCE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ariana_grande-7rings.csv',\n",
       " 'ariana_grande-no_tears_left_to_cry.csv',\n",
       " 'ariana_grande-thanku_next.csv',\n",
       " 'doja_cat-boss_bitch.csv',\n",
       " 'doja_cat-juicy.csv',\n",
       " 'doja_cat-say_so.csv',\n",
       " 'dualipa-break_my_heart.csv',\n",
       " 'dualipa-dont_start_now.csv',\n",
       " 'dualipa-new_rules.csv',\n",
       " 'fifth_harmony-dont_say_you_love_me.csv',\n",
       " 'fifth_harmony-work_from_home.csv',\n",
       " 'fifth_harmony-worth_it.csv',\n",
       " 'in_real_life-eyes_closed.csv',\n",
       " 'in_real_life-she_do.csv',\n",
       " 'in_real_life-tatoo.csv',\n",
       " 'in_real_life-tonight_belongs_to_you.csv',\n",
       " 'justin_bieber-sorry.csv',\n",
       " 'justin_bieber-what_do_you_mean.csv',\n",
       " 'justin_bieber-yummy.csv',\n",
       " 'little_mix-power.csv',\n",
       " 'little_mix-shout_out_to_my_ex.csv',\n",
       " 'little_mix-wasabi.csv',\n",
       " 'onedirection-drag_me_down.csv',\n",
       " 'onedirection-history.csv',\n",
       " 'onedirection-perfect.csv',\n",
       " 'prettymuch-blind.csv',\n",
       " 'prettymuch-me_necesita.csv',\n",
       " 'prettymuch-teacher.csv',\n",
       " 'why_dont_we-8letters.csv',\n",
       " 'why_dont_we-chills.csv',\n",
       " 'why_dont_we-trust_fund_baby.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artists(file_lists):\n",
    "    artists = dict()\n",
    "    for filename in file_lists:\n",
    "        artist_name = filename.split('-')[0]\n",
    "        title = filename.split('-')[1]\n",
    "        \n",
    "        if artist_name in artists:\n",
    "            artists[artist_name].append(title)\n",
    "        else:\n",
    "            artists[artist_name] = list()\n",
    "            artists[artist_name].append(title)\n",
    "    \n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist(filename):\n",
    "    artist_name = filename.split('-')[0]\n",
    "    return artist_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_lists = get_artists(file_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ariana_grande': ['7rings.csv',\n",
       "  'no_tears_left_to_cry.csv',\n",
       "  'thanku_next.csv'],\n",
       " 'doja_cat': ['boss_bitch.csv', 'juicy.csv', 'say_so.csv'],\n",
       " 'dualipa': ['break_my_heart.csv', 'dont_start_now.csv', 'new_rules.csv'],\n",
       " 'fifth_harmony': ['dont_say_you_love_me.csv',\n",
       "  'work_from_home.csv',\n",
       "  'worth_it.csv'],\n",
       " 'in_real_life': ['eyes_closed.csv',\n",
       "  'she_do.csv',\n",
       "  'tatoo.csv',\n",
       "  'tonight_belongs_to_you.csv'],\n",
       " 'justin_bieber': ['sorry.csv', 'what_do_you_mean.csv', 'yummy.csv'],\n",
       " 'little_mix': ['power.csv', 'shout_out_to_my_ex.csv', 'wasabi.csv'],\n",
       " 'onedirection': ['drag_me_down.csv', 'history.csv', 'perfect.csv'],\n",
       " 'prettymuch': ['blind.csv', 'me_necesita.csv', 'teacher.csv'],\n",
       " 'why_dont_we': ['8letters.csv', 'chills.csv', 'trust_fund_baby.csv']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 형용사 Top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_hangul(d):\n",
    "    for key, values in d.items():        \n",
    "        adj_list = list()\n",
    "        \n",
    "        print('-------------' + key + '-------------')\n",
    "        for value in values:\n",
    "            file_name = key + '-' + value\n",
    "            \n",
    "            print(file_name)\n",
    "            \n",
    "            df = pd.read_csv(SOURCE_PATH + file_name, sep=',')\n",
    "            hangul_df = df[df['hangul']==True]['contents']\n",
    "\n",
    "            for idx, document in enumerate(hangul_df):\n",
    "                okt = konlpy.tag.Okt()\n",
    "                for word in okt.pos(document, stem=True):\n",
    "                    if word[1] in ['Adjective']:\n",
    "                        adj_list.append(word[0])\n",
    "        \n",
    "        count = Counter(adj_list)\n",
    "        most_count = count.most_common(100)\n",
    "        \n",
    "        save_path = TARGET_PATH + key + '.csv'\n",
    "\n",
    "        mode = 'a' if os.path.isfile(save_path) else 'w'\n",
    "\n",
    "        with open(save_path, encoding='utf-8-sig', mode=mode) as f:\n",
    "            for tag in most_count:\n",
    "                f.write('{},{}\\n'.format(tag[0], tag[1]))\n",
    "        \n",
    "        print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_hangul(artist_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영어 형용사 Top 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_english(d):\n",
    "    for key, values in d.items():        \n",
    "        adj_list = list()\n",
    "        \n",
    "        print('-------------' + key + '-------------')\n",
    "        for value in values:\n",
    "            file_name = key + '-' + value\n",
    "            \n",
    "            print(file_name)\n",
    "            \n",
    "            df = pd.read_csv(SOURCE_PATH + file_name, sep=',')\n",
    "            eng_df = df[df['hangul']==False]['contents']\n",
    "            \n",
    "            for idx, contents in enumerate(eng_df):\n",
    "                try:\n",
    "                    for word in nltk.tag.pos_tag(nltk.tokenize.word_tokenize(contents)):  \n",
    "                        if word[1] in ['JJ']:\n",
    "                            adj_list.append(word[0])\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        count = Counter(adj_list)\n",
    "        most_count = count.most_common(200)\n",
    "        \n",
    "        save_path = TARGET_PATH + key + '.csv'\n",
    "\n",
    "        mode = 'a' if os.path.isfile(save_path) else 'w'\n",
    "\n",
    "        with open(save_path, encoding='utf-8-sig', mode=mode) as f:\n",
    "            for tag in most_count:\n",
    "                f.write('{},{}\\n'.format(tag[0], tag[1]))\n",
    "        \n",
    "        print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------ariana_grande-------------\n",
      "ariana_grande-7rings.csv\n",
      "ariana_grande-no_tears_left_to_cry.csv\n",
      "ariana_grande-thanku_next.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\ariana_grande.csv\n",
      "-------------doja_cat-------------\n",
      "doja_cat-boss_bitch.csv\n",
      "doja_cat-juicy.csv\n",
      "doja_cat-say_so.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\doja_cat.csv\n",
      "-------------dualipa-------------\n",
      "dualipa-break_my_heart.csv\n",
      "dualipa-dont_start_now.csv\n",
      "dualipa-new_rules.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\dualipa.csv\n",
      "-------------fifth_harmony-------------\n",
      "fifth_harmony-dont_say_you_love_me.csv\n",
      "fifth_harmony-work_from_home.csv\n",
      "fifth_harmony-worth_it.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\fifth_harmony.csv\n",
      "-------------in_real_life-------------\n",
      "in_real_life-eyes_closed.csv\n",
      "in_real_life-she_do.csv\n",
      "in_real_life-tatoo.csv\n",
      "in_real_life-tonight_belongs_to_you.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\in_real_life.csv\n",
      "-------------justin_bieber-------------\n",
      "justin_bieber-sorry.csv\n",
      "justin_bieber-what_do_you_mean.csv\n",
      "justin_bieber-yummy.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\justin_bieber.csv\n",
      "-------------little_mix-------------\n",
      "little_mix-power.csv\n",
      "little_mix-shout_out_to_my_ex.csv\n",
      "little_mix-wasabi.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\little_mix.csv\n",
      "-------------onedirection-------------\n",
      "onedirection-drag_me_down.csv\n",
      "onedirection-history.csv\n",
      "onedirection-perfect.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\onedirection.csv\n",
      "-------------prettymuch-------------\n",
      "prettymuch-blind.csv\n",
      "prettymuch-me_necesita.csv\n",
      "prettymuch-teacher.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\prettymuch.csv\n",
      "-------------why_dont_we-------------\n",
      "why_dont_we-8letters.csv\n",
      "why_dont_we-chills.csv\n",
      "why_dont_we-trust_fund_baby.csv\n",
      "D:\\02-yscec\\2020-1\\DataVisualization\\final-term\\preprocess_data\\tokenized-show\\internal\\why_dont_we.csv\n"
     ]
    }
   ],
   "source": [
    "iterative_english(artist_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
